---
permalink: /notes/
title: "Miscellaneous Notes"
author_profile: true
redirect_from: 
  - /notes.html
---

# Math

[Derivative Rules](http://www.mathsisfun.com/calculus/derivatives-rules.html)

[And](https://en.wikipedia.org/wiki/Differentiation_rules)

# History
From [this article](http://sdtimes.com/realities-machine-learning-systems/):

"...in 1957, psychologist Frank Rosenblatt invented the perceptron, or an algorithm for supervised learning of binary classifiers."

Find or write up a brief description of the Perceptron and maybe a couple of other important ML advances.


# Classes/Education

[How to Learn Deep Learning when you're not a CS PhD](https://vimeo.com/214233053)

[A concise introductory course on probabilistic graphical models](https://ermongroup.github.io/cs228-notes/)


# [The Myth of a Superhuman AI](https://backchannel.com/the-myth-of-a-superhuman-ai-59282b686c62)

1. Intelligence is not a single dimension, so “smarter than humans” is a meaningless concept.

   I completely agree with the first part, but even in his own text he shows many examples of how "smarter than human's" is not at all meaningless. "AlphaGo is smarter than the best human Go player, possibly smarter than all humans put together." That's completely accurate and not at all meaningless as long as it's understood in the context of playing Go. There are also plenty of mathematical tools for reducing dimensionality so that we should be able to reason about and compare different minds under a high dimensional concept of intelligence.

2. Humans do not have general purpose minds, and neither will AIs.

   It seems to me that this is one of the dimensions of intelligence, with some types of minds more general purpose and others not so much. Right now humans are probably farther along toward general purpose than any other minds we know of. Whether AI's will ever be more general purpose than us is an open question. Or even whether they'll ever be much more than single purpose, e.g. Alpha Go or autonomous vehicles.

3. Emulation of human thinking in other media will be constrained by cost.

   This title seems to be misleading since human thinking itself is also constrained by cost. I don't think I've ever heard of a Machine Learning system that was **more** expensive than the human system it was meant to replace. What would be the point in developing that?

   The section where he discusses this title doesn't actually seem to talk about costs but rather about how similar or dissimilar non-human minds will be from our own.

4. Dimensions of intelligence are not infinite.

   Almost certainly true. However my very limited understanding is that the human brain is many orders of magnitude away from theoretical limits of computation. Computation limit of the mass of a human brain, based on [Bremermann's Limit](https://en.wikipedia.org/wiki/Bremermann%27s_limit): ~2 x 10^50 bits per second. Estimates of the actual computational power of a human brain from [Merkle](http://www.merkle.com/brainLimits.html): 10^13 to 10^16 operations per second. How those two units compare, I'm not sure.

5. Intelligences are only one factor in progress.

   This argument is by far the most persuasive.
