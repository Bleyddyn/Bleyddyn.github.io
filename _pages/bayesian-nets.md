---
layout: archive
title: "Bayesian Nets"
permalink: /bayesian-nets/
author_profile: true
---

{% include base_path %}


* [Deep Prior](https://arxiv.org/abs/1712.05016)
* [Weight Uncertainty in Neural Networks](https://arxiv.org/abs/1505.05424), e.g. Bayes by Backprop
  * Follow-on paper: [Bayesian Hypernetworks](https://arxiv.org/abs/1710.04759)
    * Train a neural net to output the distribution of the desired neural net.
    * Once trained, input random noise to sample the parameters of the desired net.
    * A lot of the algorithm has to do with being able to scale up to lots of parameters.
* [Variational Dropout and the Local Reparameterization Trick](https://arxiv.org/abs/1506.02557)
* [Dropout as a bayesian approximation: Representing model uncertainty in deep learning](https://arxiv.org/abs/1506.02142)
* [An Approximate Bayesian Long Short-Term Memory Algorithm for Outlier Detection](https://arxiv.org/abs/1712.08773)
* [Probabilistic supervised learning](https://arxiv.org/abs/1801.00753)
* [Using Deep Neural Network Approximate Bayesian Network](https://arxiv.org/abs/1801.00282)

---
